{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyasJothish/ai-platform/blob/master/tasks/methodology/word-embeddings/Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAR7KBmaOGtu",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings using Word2Vec.\n",
        "\n",
        "### Procedure\n",
        "\n",
        "1) I shall be working with [Fake News data](https://www.kaggle.com/mrisdal/fake-news) from Kaggle as an example for Word Embedding.\n",
        "\n",
        "This data set has sufficient data containing documents to train the model on.\n",
        "\n",
        "2) Clean/Tokenize the documents in the data set.\n",
        "\n",
        "3) Vectorize the model using Word2Vec and explore the results like finding most similar words, finding similarity and differences.\n",
        "\n",
        "[gensim](https://radimrehurek.com/gensim/) package is used for Word2Vec functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5lYo4K8wEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbvXDS8_R7ww",
        "colab_type": "code",
        "outputId": "2766e8cd-7da1-4412-d85b-388f9f55de04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "!pip install -U gensim\n",
        "import gensim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/3d/89b27573f56abcd1b8c9598b240f53c45a3c79aa0924a24588e99716043b/gensim-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (1.9.180)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.180 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.180)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (2019.6.16)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.180->boto3->smart-open>=1.7.0->gensim) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.180->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5aWa2PRcIe",
        "colab_type": "text"
      },
      "source": [
        "### Downloading Kaggle data set\n",
        "\n",
        "1. You'll have to sign up for Kaggle and [authorize](https://github.com/Kaggle/kaggle-api#api-credentials) the API.\n",
        "\n",
        "2. Specify the path for accessing the kaggle.json file. For Colab we can store the kaggle.json on Google Drive.\n",
        "\n",
        "3. Download Fake News Data.\n",
        "\n",
        "4. The data is present in compressed form this needs to be unzipped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ISgBVb8IRs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8cc2843e-8cf6-413f-eba1-0e39638f8463"
      },
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%env KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n",
        "\n",
        "!kaggle datasets download -d mrisdal/fake-news\n",
        "\n",
        "!unzip fake-news.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "env: KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n",
            "Downloading fake-news.zip to /content\n",
            " 34% 7.00M/20.4M [00:00<00:00, 72.2MB/s]\n",
            "100% 20.4M/20.4M [00:00<00:00, 99.9MB/s]\n",
            "Archive:  fake-news.zip\n",
            "  inflating: fake.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCHcbCBGRd-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"fake.csv\")\n",
        "df['title_text'] = df['title'] + df ['text']\n",
        "df.drop(columns=['uuid', 'ord_in_thread', 'author', 'published', 'title', 'text',\n",
        "       'language', 'crawled', 'site_url', 'country', 'domain_rank',\n",
        "       'thread_title', 'spam_score', 'main_img_url', 'replies_count',\n",
        "       'participants_count', 'likes', 'comments', 'shares', 'type'], inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.title_text = df.title_text.str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsZNC-wcSuAd",
        "colab_type": "text"
      },
      "source": [
        "### Data cleaning\n",
        "\n",
        "1. The information related to document is contained in **title** and **text** columns. So I shall be using only these two columns.\n",
        "\n",
        "2. Turn a document into clean tokens.\n",
        "\n",
        "3. Build the model using gensim."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSDN6X27Tozm",
        "colab_type": "code",
        "outputId": "6a456d5e-88a6-49af-ec3f-8e02b8de4494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>muslims busted: they stole millions in gov’t b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>re: why did attorney general loretta lynch ple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breaking: weiner cooperating with fbi on hilla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic! trump's 7 point plan to reform heal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          title_text\n",
              "0  muslims busted: they stole millions in gov’t b...\n",
              "1  re: why did attorney general loretta lynch ple...\n",
              "2  breaking: weiner cooperating with fbi on hilla...\n",
              "3  pin drop speech by father of daughter kidnappe...\n",
              "4  fantastic! trump's 7 point plan to reform heal..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_4C2GVcUr8k",
        "colab_type": "code",
        "outputId": "0e03a944-57e6-4cb1-a04c-cd230a7a873c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_doc(doc):\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\ttokens = [word for word in tokens if len(word) > 1]\n",
        "\treturn tokens\n",
        "\n",
        "df['cleaned'] = df.title_text.apply(clean_doc)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12273, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title_text</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>muslims busted: they stole millions in gov’t b...</td>\n",
              "      <td>[muslims, busted, they, stole, millions, in, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>re: why did attorney general loretta lynch ple...</td>\n",
              "      <td>[re, why, did, attorney, general, loretta, lyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breaking: weiner cooperating with fbi on hilla...</td>\n",
              "      <td>[breaking, weiner, cooperating, with, fbi, on,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
              "      <td>[pin, drop, speech, by, father, of, daughter, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic! trump's 7 point plan to reform heal...</td>\n",
              "      <td>[fantastic, trumps, point, plan, to, reform, h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          title_text                                            cleaned\n",
              "0  muslims busted: they stole millions in gov’t b...  [muslims, busted, they, stole, millions, in, b...\n",
              "1  re: why did attorney general loretta lynch ple...  [re, why, did, attorney, general, loretta, lyn...\n",
              "2  breaking: weiner cooperating with fbi on hilla...  [breaking, weiner, cooperating, with, fbi, on,...\n",
              "3  pin drop speech by father of daughter kidnappe...  [pin, drop, speech, by, father, of, daughter, ...\n",
              "4  fantastic! trump's 7 point plan to reform heal...  [fantastic, trumps, point, plan, to, reform, h..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq9lO4tKVUGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v = Word2Vec(df.cleaned, min_count=20, window=3, size=300, negative=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F83kX2MCcCmp",
        "colab_type": "code",
        "outputId": "75612c34-616d-4a4d-a5b0-68fbfa189075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words = list(w2v.wv.vocab)\n",
        "print(f'Vocabulary Size: {len(words)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 18717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jx-HjsTWK7Z",
        "colab_type": "text"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Explore the results like finding most similar words, finding similarity and differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJAMEJRscHNh",
        "colab_type": "code",
        "outputId": "56dc16eb-8600-419c-bcd6-7fb6451c009e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "w2v.wv.most_similar('trump', topn=15)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('trumps', 0.618967592716217),\n",
              " ('rumsfeld', 0.49241888523101807),\n",
              " ('duck', 0.46330875158309937),\n",
              " ('hillary', 0.4494830369949341),\n",
              " ('victory', 0.4427679181098938),\n",
              " ('landslide', 0.43222731351852417),\n",
              " ('he', 0.42894965410232544),\n",
              " ('candidacy', 0.4243707060813904),\n",
              " ('presidentelect', 0.42006194591522217),\n",
              " ('rhetoric', 0.4104347825050354),\n",
              " ('sanders', 0.393967866897583),\n",
              " ('bernie', 0.39254146814346313),\n",
              " ('candidate', 0.38946977257728577),\n",
              " ('hrc', 0.3869854807853699),\n",
              " ('kaine', 0.38659706711769104)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_CS60QLcfo-",
        "colab_type": "code",
        "outputId": "1396e9ee-db03-474a-99ad-2a76eafa4420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "w2v.wv.most_similar(positive=[\"fbi\"], topn=15)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('comey', 0.6337319016456604),\n",
              " ('doj', 0.5546440482139587),\n",
              " ('bureau', 0.5245726108551025),\n",
              " ('nypd', 0.49104368686676025),\n",
              " ('pentagon', 0.47721385955810547),\n",
              " ('cia', 0.4757136106491089),\n",
              " ('reopened', 0.46825480461120605),\n",
              " ('weiner', 0.46098488569259644),\n",
              " ('investigation', 0.4488767981529236),\n",
              " ('fbis', 0.44131773710250854),\n",
              " ('dea', 0.4372154474258423),\n",
              " ('investigators', 0.41698330640792847),\n",
              " ('fsb', 0.41560107469558716),\n",
              " ('nsa', 0.41324031352996826),\n",
              " ('probe', 0.41144895553588867)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyWnhEhHct4k",
        "colab_type": "code",
        "outputId": "e6ffa71c-4af5-4997-bbec-6ca487bbb718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "w2v.wv.doesnt_match(['fbi', 'cat', 'nypd'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbXJT9XpdVmk",
        "colab_type": "code",
        "outputId": "a107ad5d-6dbc-4ddd-cb2f-b69993513c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w2v.wv.similarity(\"fbi\",\"nypd\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4910437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpTFjAd4X_9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2006d87-41f7-46ec-c3c2-1062e7265112"
      },
      "source": [
        "w2v.wv.similarity(\"fbi\",\"trump\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19102131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}